{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e553cfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Neural Operator Examples with PyTorch\n",
      "======================================================================\n",
      "\n",
      "[1] Basic FNO\n",
      "----------------------------------------------------------------------\n",
      "FNO Input shape: torch.Size([16, 2, 64, 64])\n",
      "FNO Output shape: torch.Size([16, 1, 64, 64])\n",
      "\n",
      "[2] Tensorized FNO (TFNO)\n",
      "----------------------------------------------------------------------\n",
      "TFNO Total parameters: 500,833\n",
      "TFNO Output shape: torch.Size([16, 1, 64, 64])\n",
      "\n",
      "[4] Custom Training Loop\n",
      "----------------------------------------------------------------------\n",
      "Epoch [2/10], Loss: 32.0094\n",
      "Epoch [4/10], Loss: 32.0041\n",
      "Epoch [6/10], Loss: 32.0028\n",
      "Epoch [8/10], Loss: 32.0006\n",
      "Epoch [10/10], Loss: 32.0047\n",
      "\n",
      "[6] 1D FNO for Time-Series\n",
      "----------------------------------------------------------------------\n",
      "1D FNO Input shape: torch.Size([16, 1, 256])\n",
      "1D FNO Output shape: torch.Size([16, 1, 256])\n",
      "\n",
      "[7] 3D FNO for Volumetric Data\n",
      "----------------------------------------------------------------------\n",
      "3D FNO Input shape: torch.Size([4, 4, 32, 32, 32])\n",
      "3D FNO Output shape: torch.Size([4, 4, 32, 32, 32])\n",
      "\n",
      "[8] Super-Resolution (Resolution Invariance)\n",
      "----------------------------------------------------------------------\n",
      "Training resolution: torch.Size([16, 2, 32, 32])\n",
      "Testing resolution: torch.Size([4, 2, 128, 128])\n",
      "Super-resolution output: torch.Size([4, 1, 128, 128])\n",
      "✓ Same model works on different resolutions!\n",
      "\n",
      "[10] Physics-Informed Loss\n",
      "----------------------------------------------------------------------\n",
      "Data loss: 16.0023\n",
      "Physics loss: 0.0000\n",
      "Total loss: 16.0023\n",
      "\n",
      "======================================================================\n",
      "Examples completed! Check individual functions for details.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Neural Operator Examples with PyTorch\n",
    "======================================\n",
    "Comprehensive examples showing different neural operator architectures\n",
    "and training workflows using the neuraloperator library.\n",
    "\n",
    "Installation:\n",
    "pip install neuraloperator torch\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# ============================================================================\n",
    "# Example 1: Basic Fourier Neural Operator (FNO)\n",
    "# ============================================================================\n",
    "\n",
    "def example_1_basic_fno():\n",
    "    \"\"\"\n",
    "    Basic FNO for 2D problems like Darcy Flow or solving PDEs.\n",
    "    FNO learns mappings between function spaces in the Fourier domain.\n",
    "    \"\"\"\n",
    "    from neuralop.models import FNO\n",
    "    \n",
    "    # Create FNO model\n",
    "    model = FNO(\n",
    "        n_modes=(32, 32),        # Number of Fourier modes to use\n",
    "        hidden_channels=64,       # Hidden layer dimension\n",
    "        in_channels=2,            # Input function channels (e.g., coordinates)\n",
    "        out_channels=1,           # Output function channels (e.g., solution)\n",
    "        n_layers=4                # Number of Fourier layers\n",
    "    )\n",
    "    \n",
    "    # Example input: batch of 2D functions\n",
    "    batch_size = 16\n",
    "    resolution = 64\n",
    "    x = torch.randn(batch_size, 2, resolution, resolution)\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    print(f\"FNO Input shape: {x.shape}\")\n",
    "    print(f\"FNO Output shape: {output.shape}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Example 2: Tensorized FNO (TFNO) - Memory Efficient\n",
    "# ============================================================================\n",
    "\n",
    "def example_2_tfno():\n",
    "    \"\"\"\n",
    "    TFNO uses Tucker factorization for parameter efficiency.\n",
    "    Reduces parameters by ~95% while maintaining accuracy.\n",
    "    \"\"\"\n",
    "    from neuralop.models import TFNO\n",
    "    \n",
    "    # Create TFNO model with Tucker factorization\n",
    "    model = TFNO(\n",
    "        n_modes=(32, 32),\n",
    "        hidden_channels=64,\n",
    "        in_channels=2,\n",
    "        out_channels=1,\n",
    "        factorization='tucker',   # Tucker decomposition\n",
    "        implementation='factorized',  # Efficient implementation\n",
    "        rank=0.05                 # Use only 5% of parameters\n",
    "    )\n",
    "    \n",
    "    # Example usage\n",
    "    x = torch.randn(16, 2, 64, 64)\n",
    "    output = model(x)\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"TFNO Total parameters: {total_params:,}\")\n",
    "    print(f\"TFNO Output shape: {output.shape}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Example 3: Complete Training Loop with Darcy Flow Dataset\n",
    "# ============================================================================\n",
    "\n",
    "def example_3_training_loop():\n",
    "    \"\"\"\n",
    "    Complete training example using the built-in Darcy Flow dataset.\n",
    "    Shows data loading, model creation, and training.\n",
    "    \"\"\"\n",
    "    from neuralop.models import FNO\n",
    "    from neuralop.data.datasets import load_darcy_flow_small\n",
    "    from neuralop.training import Trainer\n",
    "    from neuralop.losses import LpLoss\n",
    "    \n",
    "    # Load Darcy Flow dataset\n",
    "    train_loader, test_loaders, data_processor = load_darcy_flow_small(\n",
    "        n_train=1000,\n",
    "        batch_size=32,\n",
    "        n_tests=[100],\n",
    "        test_resolutions=[32],\n",
    "        test_batch_sizes=[32],\n",
    "    )\n",
    "    \n",
    "    # Create model\n",
    "    model = FNO(\n",
    "        n_modes=(16, 16),\n",
    "        hidden_channels=32,\n",
    "        in_channels=3,   # x, y coordinates + input field\n",
    "        out_channels=1   # solution field\n",
    "    )\n",
    "    \n",
    "    # Setup optimizer and scheduler\n",
    "    optimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    scheduler = StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "    \n",
    "    # Define losses\n",
    "    train_loss = LpLoss(d=2, p=2)\n",
    "    eval_losses = {'l2': LpLoss(d=2, p=2)}\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        n_epochs=20,\n",
    "        data_processor=data_processor,\n",
    "        device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train(\n",
    "        train_loader=train_loader,\n",
    "        test_loaders=test_loaders,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        regularizer=False,\n",
    "        training_loss=train_loss,\n",
    "        eval_losses=eval_losses\n",
    "    )\n",
    "    \n",
    "    # Save model\n",
    "    model.save_checkpoint(save_folder='./checkpoints/', save_name='darcy_fno')\n",
    "    print(\"Model saved successfully!\")\n",
    "    \n",
    "    return model, trainer\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Example 4: Custom Training Loop (More Control)\n",
    "# ============================================================================\n",
    "\n",
    "def example_4_custom_training():\n",
    "    \"\"\"\n",
    "    Manual training loop for more control over the training process.\n",
    "    \"\"\"\n",
    "    from neuralop.models import FNO\n",
    "    from neuralop.losses import LpLoss\n",
    "    \n",
    "    # Create model\n",
    "    model = FNO(n_modes=(16, 16), hidden_channels=32, in_channels=2, out_channels=1)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = LpLoss(d=2, p=2)\n",
    "    optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    # Dummy training data\n",
    "    n_epochs = 10\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        # Generate dummy batch\n",
    "        x = torch.randn(32, 2, 64, 64).to(device)\n",
    "        y = torch.randn(32, 1, 64, 64).to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{n_epochs}], Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Example 5: Geometry-Informed Neural Operator (GINO)\n",
    "# ============================================================================\n",
    "\n",
    "def example_5_gino():\n",
    "    \"\"\"\n",
    "    GINO for irregular geometries and unstructured meshes.\n",
    "    Combines FNO with graph neural networks.\n",
    "    \"\"\"\n",
    "    from neuralop.models import GINO\n",
    "    \n",
    "    # Create GINO model\n",
    "    model = GINO(\n",
    "        in_channels=3,           # Input features\n",
    "        out_channels=1,          # Output features\n",
    "        gno_coord_dim=2,         # 2D coordinates\n",
    "        projection_channels=64,   # Projection dimension\n",
    "        gno_radius=0.1,          # Neighborhood radius for graph\n",
    "        n_layers=4\n",
    "    )\n",
    "    \n",
    "    # Example with irregular points\n",
    "    batch_size = 8\n",
    "    n_points = 1000\n",
    "    \n",
    "    # Points at irregular locations\n",
    "    x = torch.randn(batch_size, n_points, 3)  # (batch, points, features)\n",
    "    pos = torch.rand(batch_size, n_points, 2)  # (batch, points, 2D coords)\n",
    "    \n",
    "    output = model(x, pos)\n",
    "    print(f\"GINO Input shape: {x.shape}\")\n",
    "    print(f\"GINO Output shape: {output.shape}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Example 6: 1D Time-Series with FNO\n",
    "# ============================================================================\n",
    "\n",
    "def example_6_fno_1d_timeseries():\n",
    "    \"\"\"\n",
    "    Using FNO for 1D problems like Burgers equation or time-series.\n",
    "    \"\"\"\n",
    "    from neuralop.models import FNO\n",
    "    \n",
    "    # 1D FNO\n",
    "    model = FNO(\n",
    "        n_modes=(64,),           # 1D Fourier modes\n",
    "        hidden_channels=64,\n",
    "        in_channels=1,           # Single input channel\n",
    "        out_channels=1,          # Single output channel\n",
    "        n_layers=4\n",
    "    )\n",
    "    \n",
    "    # Example 1D signal\n",
    "    batch_size = 16\n",
    "    time_steps = 256\n",
    "    x = torch.randn(batch_size, 1, time_steps)\n",
    "    \n",
    "    output = model(x)\n",
    "    print(f\"1D FNO Input shape: {x.shape}\")\n",
    "    print(f\"1D FNO Output shape: {output.shape}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Example 7: 3D FNO for Volumetric Data\n",
    "# ============================================================================\n",
    "\n",
    "def example_7_fno_3d():\n",
    "    \"\"\"\n",
    "    3D FNO for volumetric problems like 3D fluid dynamics.\n",
    "    \"\"\"\n",
    "    from neuralop.models import FNO\n",
    "    \n",
    "    # 3D FNO\n",
    "    model = FNO(\n",
    "        n_modes=(16, 16, 16),    # 3D Fourier modes\n",
    "        hidden_channels=32,\n",
    "        in_channels=4,           # e.g., velocity (3) + pressure (1)\n",
    "        out_channels=4,\n",
    "        n_layers=4\n",
    "    )\n",
    "    \n",
    "    # Example 3D volume\n",
    "    batch_size = 4\n",
    "    resolution = 32\n",
    "    x = torch.randn(batch_size, 4, resolution, resolution, resolution)\n",
    "    \n",
    "    output = model(x)\n",
    "    print(f\"3D FNO Input shape: {x.shape}\")\n",
    "    print(f\"3D FNO Output shape: {output.shape}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Example 8: Model Inference and Super-Resolution\n",
    "# ============================================================================\n",
    "\n",
    "def example_8_super_resolution():\n",
    "    \"\"\"\n",
    "    Neural operators are resolution-invariant!\n",
    "    Train at one resolution, test at another.\n",
    "    \"\"\"\n",
    "    from neuralop.models import FNO\n",
    "    \n",
    "    # Create and train model at low resolution\n",
    "    model = FNO(\n",
    "        n_modes=(16, 16),\n",
    "        hidden_channels=64,\n",
    "        in_channels=2,\n",
    "        out_channels=1\n",
    "    )\n",
    "    \n",
    "    # Train on 32x32 data\n",
    "    x_train = torch.randn(16, 2, 32, 32)\n",
    "    output_train = model(x_train)\n",
    "    print(f\"Training resolution: {x_train.shape}\")\n",
    "    \n",
    "    # Test on 128x128 data (4x higher resolution!)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x_test = torch.randn(4, 2, 128, 128)\n",
    "        output_test = model(x_test)\n",
    "    \n",
    "    print(f\"Testing resolution: {x_test.shape}\")\n",
    "    print(f\"Super-resolution output: {output_test.shape}\")\n",
    "    print(\"✓ Same model works on different resolutions!\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Example 9: Loading Pretrained Models\n",
    "# ============================================================================\n",
    "\n",
    "def example_9_load_checkpoint():\n",
    "    \"\"\"\n",
    "    Save and load model checkpoints.\n",
    "    \"\"\"\n",
    "    from neuralop.models import FNO\n",
    "    \n",
    "    # Create and save model\n",
    "    model = FNO(n_modes=(16, 16), hidden_channels=64, in_channels=2, out_channels=1)\n",
    "    model.save_checkpoint(save_folder='./checkpoints/', save_name='my_fno_model')\n",
    "    print(\"Model saved!\")\n",
    "    \n",
    "    # Load model later\n",
    "    loaded_model = FNO.from_checkpoint(\n",
    "        save_folder='./checkpoints/',\n",
    "        save_name='my_fno_model'\n",
    "    )\n",
    "    print(\"Model loaded!\")\n",
    "    \n",
    "    return loaded_model\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Example 10: Physics-Informed Loss\n",
    "# ============================================================================\n",
    "\n",
    "def example_10_physics_informed():\n",
    "    \"\"\"\n",
    "    Combine data-driven learning with physics-based constraints.\n",
    "    \"\"\"\n",
    "    from neuralop.models import FNO\n",
    "    from neuralop.losses import LpLoss\n",
    "    \n",
    "    model = FNO(n_modes=(16, 16), hidden_channels=64, in_channels=2, out_channels=1)\n",
    "    data_loss = LpLoss(d=2, p=2)\n",
    "    \n",
    "    def physics_loss(pred, x):\n",
    "        \"\"\"\n",
    "        Example: enforce smoothness or conservation laws\n",
    "        \"\"\"\n",
    "        # Compute gradients using autograd\n",
    "        pred.requires_grad_(True)\n",
    "        grad = torch.autograd.grad(pred.sum(), x, create_graph=True)[0]\n",
    "        \n",
    "        # Example: penalize large gradients (smoothness)\n",
    "        smooth_loss = torch.mean(grad ** 2)\n",
    "        return smooth_loss\n",
    "    \n",
    "    # Training step\n",
    "    x = torch.randn(16, 2, 64, 64, requires_grad=True)\n",
    "    y = torch.randn(16, 1, 64, 64)\n",
    "    \n",
    "    pred = model(x)\n",
    "    \n",
    "    # Combined loss\n",
    "    loss_data = data_loss(pred, y)\n",
    "    loss_physics = physics_loss(pred, x)\n",
    "    total_loss = loss_data + 0.1 * loss_physics\n",
    "    \n",
    "    print(f\"Data loss: {loss_data.item():.4f}\")\n",
    "    print(f\"Physics loss: {loss_physics.item():.4f}\")\n",
    "    print(f\"Total loss: {total_loss.item():.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Main execution\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Neural Operator Examples with PyTorch\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\\n[1] Basic FNO\")\n",
    "    print(\"-\" * 70)\n",
    "    example_1_basic_fno()\n",
    "    \n",
    "    print(\"\\n[2] Tensorized FNO (TFNO)\")\n",
    "    print(\"-\" * 70)\n",
    "    example_2_tfno()\n",
    "    \n",
    "    print(\"\\n[4] Custom Training Loop\")\n",
    "    print(\"-\" * 70)\n",
    "    example_4_custom_training()\n",
    "    \n",
    "    print(\"\\n[6] 1D FNO for Time-Series\")\n",
    "    print(\"-\" * 70)\n",
    "    example_6_fno_1d_timeseries()\n",
    "    \n",
    "    print(\"\\n[7] 3D FNO for Volumetric Data\")\n",
    "    print(\"-\" * 70)\n",
    "    example_7_fno_3d()\n",
    "    \n",
    "    print(\"\\n[8] Super-Resolution (Resolution Invariance)\")\n",
    "    print(\"-\" * 70)\n",
    "    example_8_super_resolution()\n",
    "    \n",
    "    print(\"\\n[10] Physics-Informed Loss\")\n",
    "    print(\"-\" * 70)\n",
    "    example_10_physics_informed()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"Examples completed! Check individual functions for details.\")\n",
    "    print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
